{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vhAMaIOBIee"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wO0InzL66URu"
   },
   "source": [
    "### Retrieve the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN-Pc6Zd6awg"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "train_data_dir = 'data/data_itay_profile/patch_train_itay_binary_10000_350x350_fb'\n",
    "train_data_dir = pathlib.Path(train_data_dir)\n",
    "test_data_dir = 'data/data_itay_profile/patch_val_itay_binary_2000_350x350_fb'\n",
    "test_data_dir = pathlib.Path(test_data_dir)\n",
    "blind_test_data_dir = 'data/data_itay_profile/patch_test_itay_binary_2000_350x350_fb'\n",
    "blind_test_data_dir = pathlib.Path(blind_test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhewYCxhXQBX"
   },
   "outputs": [],
   "source": [
    "train_image_count = len(list(train_data_dir.glob('*/*.png')))\n",
    "train_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhewYCxhXQBX"
   },
   "outputs": [],
   "source": [
    "test_image_count = len(list(test_data_dir.glob('*/*.png')))\n",
    "test_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_test_image_count = len(list(blind_test_data_dir.glob('*/*.png')))\n",
    "blind_test_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ1HKKdR4A7c"
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_data_dir.glob('*')])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLASS_NAMES = np.array([item.name for item in test_data_dir.glob('*')])\n",
    "TEST_CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLIND_CLASS_NAMES = np.array([item.name for item in blind_test_data_dir.glob('*')])\n",
    "BLIND_CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zf695or-Flq"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 16\n",
    "NUMBER_OF_EPOCHS = 15\n",
    "TRAIN_STEPS_PER_EPOCH = np.ceil(train_image_count/BATCH_SIZE)\n",
    "TEST_STEPS_PER_EPOCH = np.ceil(test_image_count/BATCH_SIZE)\n",
    "IMG_HEIGHT = 350\n",
    "IMG_WIDTH = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLp0XVG_Vgi2"
   },
   "outputs": [],
   "source": [
    "def show_logical_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(7,7))\n",
    "  for n in range(9):\n",
    "      ax = plt.subplot(3,3,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_numerical_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(7,7))\n",
    "  for n in range(9):\n",
    "      ax = plt.subplot(3,3,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      plt.title(CLASS_NAMES[label_batch[n]])\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIG5CPaULegg"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAkQp5uxoINu"
   },
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.list_files(str(train_data_dir/'*/*'))\n",
    "test_list_ds = tf.data.Dataset.list_files(str(test_data_dir/'*/*'))\n",
    "blind_test_list_ds = tf.data.Dataset.list_files(str(blind_test_data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arSQzIey-4D4"
   },
   "outputs": [],
   "source": [
    "def get_logical_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  numeric_label=tf.argmax(tf.cast((parts[-2] == CLASS_NAMES),dtype=tf.uint8))\n",
    "  return numeric_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  onehot_label=tf.cast((parts[-2] == CLASS_NAMES),dtype=tf.uint8)\n",
    "  return onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGlq4IP4Aktb"
   },
   "outputs": [],
   "source": [
    "def decode_and_normalize_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(img):\n",
    "  img = tf.image.resize_with_crop_or_pad(img, IMG_HEIGHT + 6, IMG_WIDTH + 6)\n",
    "  img = tf.image.random_crop(img, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "  img = tf.image.random_brightness(img, 0.2)\n",
    "  img = tf.image.random_contrast(img, 0.2,0.5) \n",
    "  img = tf.image.random_saturation(img, 5,10) \n",
    "  img = tf.image.random_flip_left_right(img)\n",
    "  img = tf.image.random_flip_up_down(img)\n",
    "  img = tf.clip_by_value(img, 0, 1)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xhBRgvNqRRe"
   },
   "outputs": [],
   "source": [
    "def process_augment_path(file_path):\n",
    "  label = get_numerical_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_and_normalize_img(img)\n",
    "  img = augment(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_numerical_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_and_normalize_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SDhbo8lOBQv"
   },
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_labeled_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_labeled_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "blind_test_labeled_ds = blind_test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZmZJx8ePw_5"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds):\n",
    "  ds = ds.repeat(NUMBER_OF_EPOCHS)\n",
    "  ds = ds.shuffle(buffer_size=96)\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YKnrfAeZV10"
   },
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(train_labeled_ds)\n",
    "test_ds = prepare_for_training(test_labeled_ds)\n",
    "blind_test_ds = prepare_for_training(blind_test_labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image_batch, tf_label_batch= next(iter(train_ds))\n",
    "show_numerical_batch(tf_image_batch.numpy(), tf_label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=[ [CLASS_NAMES[item],item] for item in tf_label_batch]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN_Dnl72YNIj"
   },
   "outputs": [],
   "source": [
    "tf_image_batch, tf_label_batch= next(iter(test_ds))\n",
    "show_numerical_batch(tf_image_batch.numpy(), tf_label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=[ [CLASS_NAMES[item],item] for item in tf_label_batch]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_image_batch, tf_label_batch= next(iter(blind_test_ds))\n",
    "show_numerical_batch(tf_image_batch.numpy(), tf_label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=[ [CLASS_NAMES[item],item] for item in tf_label_batch]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSPCom-KmApV"
   },
   "source": [
    "#### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = tf.keras.applications.VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "#                                               include_top=False,\n",
    "#                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [],
   "source": [
    "#global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "#prediction_layer = tf.keras.layers.Dense(NUMBER_OF_CLASSES)\n",
    "#model = tf.keras.Sequential([\n",
    "#  base_model,\n",
    "#  global_average_layer,\n",
    "#  prediction_layer\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "  inp = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "  base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_tensor=inp,\n",
    "                                            input_shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
    "  #vgg.trainable = False\n",
    "  #x = inception.get_layer('mixed10').output\n",
    "  x = base_model.output\n",
    "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "  #x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "  output = tf.keras.layers.Dense(NUMBER_OF_CLASSES)(x)\n",
    "  model = tf.keras.models.Model(inputs = inp, outputs=output)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint('vgg.h5', monitor='val_accuracy',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdDzI75PUXrG"
   },
   "outputs": [],
   "source": [
    "model = base_model()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, epochs=NUMBER_OF_EPOCHS, \n",
    "                    validation_data=test_ds,\n",
    "                    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\n",
    "                    validation_steps=TEST_STEPS_PER_EPOCH,\n",
    "                    callbacks=[early_stop_callback,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('vgg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= model.evaluate(test_ds,steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on blind test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= model.evaluate(blind_test_ds,steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_ds=blind_test_ds.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_images=[]\n",
    "conf_labels=[]\n",
    "for batch in list(conf_ds.as_numpy_iterator()):\n",
    "    for image in batch[0]:\n",
    "        conf_images.append(image)\n",
    "    for label in batch[1]:\n",
    "        conf_labels.append(label)\n",
    "conf_images=np.asarray(conf_images)\n",
    "conf_labels=np.asarray(conf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(conf_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=tf.argmax(predictions,-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(conf_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(\n",
    "    cm, annot=True,\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_wrong_predictions=np.nonzero(predictions!=conf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predicted_images=conf_images[indices_of_wrong_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predicted_labels=conf_labels[indices_of_wrong_predictions]\n",
    "wrong_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "show_numerical_batch(wrong_predicted_images, wrong_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,80))\n",
    "\n",
    "columns=5\n",
    "for i, image in enumerate(wrong_predicted_images):\n",
    "    plt.subplot(len(wrong_predicted_images)/columns+1,columns,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.grid(None)\n",
    "    if i>50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} \\n ({})\".format(CLASS_NAMES[predicted_label],\n",
    "                                CLASS_NAMES[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(NUMBER_OF_CLASSES))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(NUMBER_OF_CLASSES), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images,test_labels=next(iter(test_ds))\n",
    "predictions=probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blind test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images,test_labels=next(iter(blind_test_ds))\n",
    "predictions=probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'data/rescaled_filtered_new_split/patch_test_2000_350x350/italiansquare/10.png'\n",
    "LAYER_NAME = 'block5_conv3'\n",
    "CLASS_INDEX=tf.argmax(tf.cast(('italiansquare' == CLASS_NAMES),dtype=tf.uint8))\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(350, 350))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img=img/255\n",
    "grad_model = tf.keras.models.Model(inputs=[model.inputs], \n",
    "                                        outputs=[model.get_layer(LAYER_NAME).output, model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img]))\n",
    "    loss = predictions[:, CLASS_INDEX]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), (350, 350))\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "img=(img*255)\n",
    "output_image = cv2.addWeighted(img.astype('uint8'), 0.5,cv2.cvtColor(cam,cv2.COLOR_BGR2RGB), 0.5, 0)\n",
    "plt.imshow(output_image)\n",
    "plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_cam(cam_model,class_index, img):\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([img]))\n",
    "        loss = predictions[:, class_index]\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    gate_f = tf.cast(output > 0, 'float32')\n",
    "    gate_r = tf.cast(grads > 0, 'float32')\n",
    "    guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "    cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "    cam = cv2.resize(cam.numpy(), (350, 350))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    img=(img*255)\n",
    "    output_image = cv2.addWeighted(img.astype('uint8'), 0.5,cv2.cvtColor(cam,cv2.COLOR_BGR2RGB), 0.5, 0)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels=next(iter(blind_test_ds))\n",
    "raw_predictions=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 6\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  predictions, true_label, img = raw_predictions[i], test_labels[i].numpy(), test_images[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  predicted_label = np.argmax(predictions)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} \\n ({})\".format(CLASS_NAMES[predicted_label],\n",
    "                                CLASS_NAMES[true_label]),\n",
    "                                color=color)  \n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  cam=gradient_cam(grad_model,true_label, img)\n",
    "  plt.imshow(cam)\n",
    "\n",
    "plt.tight_layout(pad=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pages(test_page_dir):\n",
    "    test_pages = glob.glob(test_page_dir+'/*/*.png')\n",
    "    test_labels = []\n",
    "    for page_path in test_pages:\n",
    "        label=np.argmax(os.path.split(page_path)[0].split(os.sep)[-1]==CLASS_NAMES)\n",
    "        test_labels.append(label)\n",
    "    return test_pages, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def sample_page_patches(page_image, crop_height, crop_width, number_of_samples):\n",
    "    samples=[]\n",
    "    max_x = page_image.shape[0] - crop_height\n",
    "    max_y = page_image.shape[1] - crop_width\n",
    "    for i in range(number_of_samples):\n",
    "        x = np.random.randint(0, max_x)\n",
    "        y = np.random.randint(0, max_y)\n",
    "        crop = page_image[x: x + crop_height, y: y + crop_width]\n",
    "        samples.append(crop)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from collections import Counter\n",
    "def predict_pages_raw(test_page_images,binary_test_page_images,number_of_samples):\n",
    "    test_predicts=[]\n",
    "    for i in range(len(test_page_images)):\n",
    "        print(test_page_images[i])\n",
    "        page_image = cv2.imread(test_page_images[i],0)\n",
    "        binary_page_image = cv2.imread(binary_test_page_images[i],0)\n",
    "        #page_patches=sample_page_patches(page_image, IMG_HEIGHT, IMG_WIDTH, number_of_samples)\n",
    "        page_patches = sample_patches_from_page_w_binary(page_image,binary_page_image, number_of_patches=number_of_samples)\n",
    "        patch_predicts=[]\n",
    "        for patch in page_patches:\n",
    "            patch=cv2.merge((patch,patch,patch))\n",
    "            patch = tf.image.convert_image_dtype(patch, tf.float32)\n",
    "            patch_label=np.argmax(model.predict(np.expand_dims(patch,axis=0)))\n",
    "            patch_predicts.append(patch_label)\n",
    "            print(CLASS_NAMES[patch_label])\n",
    "        c=Counter(patch_predicts)\n",
    "        print(patch_predicts)\n",
    "        print(c)\n",
    "        major_label=c.most_common()[0][0]\n",
    "        test_predicts.append(major_label)\n",
    "        print(CLASS_NAMES[major_label])\n",
    "    return test_predicts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from collections import Counter\n",
    "def predict_pages(test_page_images,binary_test_page_images,number_of_samples):\n",
    "    test_predicts=[]\n",
    "\n",
    "    for i in range(len(test_page_images)):\n",
    "        true_text_label=test_page_images[i].split('/')[4]\n",
    "        true_label=tf.argmax(tf.cast((true_text_label == CLASS_NAMES),dtype=tf.uint8))\n",
    "        page_image = cv2.imread(test_page_images[i],0)\n",
    "        binary_page_image = cv2.imread(binary_test_page_images[i],0)\n",
    "        fig,ax=plt.subplots(1,4, figsize=(30,15),dpi=150)\n",
    "        ax[0].imshow(cv2.cvtColor(page_image,cv2.COLOR_BGR2RGB))\n",
    "        ax[0].set_title(true_text_label,size=25)\n",
    "        #page_patches=sample_page_patches(page_image, IMG_HEIGHT, IMG_WIDTH, number_of_samples)\n",
    "        page_patches = sample_patches_from_page_w_binary(page_image,binary_page_image, number_of_patches=number_of_samples)\n",
    "        #img = tf.io.read_file(file_path)\n",
    "        patch_predicts=[]\n",
    "        n=1\n",
    "        for patch in page_patches:            \n",
    "            patch=cv2.merge((patch,patch,patch))\n",
    "            patch = tf.image.convert_image_dtype(patch, tf.float32)\n",
    "            patch_label=np.argmax(model.predict(np.expand_dims(patch,axis=0)))\n",
    "            patch = tf.keras.preprocessing.image.img_to_array(patch)\n",
    "            cam=gradient_cam(grad_model,true_label, patch)\n",
    "            patch_predicts.append(patch_label)\n",
    "            predicted_text_label=CLASS_NAMES[patch_label]\n",
    "            ax[n].imshow(cam)\n",
    "            ax[n].set_title(predicted_text_label, size=25)\n",
    "            n=n+1       \n",
    "        \n",
    "        plt.show()\n",
    "        c=Counter(patch_predicts)\n",
    "        major_label=c.most_common()[0][0]\n",
    "        test_predicts.append(major_label)\n",
    "        print(CLASS_NAMES[major_label])\n",
    "    return test_predicts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_page_dir = 'data/data_itay_profile/dataset_pages/test'\n",
    "test_page_images, test_page_labels=read_pages(test_page_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_test_page_dir = 'data/data_itay_profile/dataset_binary_pages/test'\n",
    "binary_test_page_images, binary_test_page_labels=read_pages(binary_test_page_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "time.sleep(1)\n",
    "test_page_predicts=predict_pages(test_page_images,binary_test_page_images,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test_page_labels=np.array(test_page_labels)\n",
    "array_test_page_predicts=np.array(test_page_predicts)\n",
    "correct=(array_test_page_labels==array_test_page_predicts)\n",
    "page_accuracy=correct.sum()/correct.size\n",
    "page_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix( test_page_labels,  test_page_predicts)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(\n",
    "    cm, annot=True,\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong predicted page images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_page_images=np.asarray(test_page_images)\n",
    "test_page_labels=np.asarray(test_page_labels)\n",
    "indices_of_wrong_predicted_pages=np.nonzero(test_page_labels!= test_page_predicts)\n",
    "wrong_predicted_pages=test_page_images[indices_of_wrong_predicted_pages]\n",
    "wrong_predicted_labels=test_page_labels[indices_of_wrong_predicted_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predicted_page_images=[]\n",
    "for path in wrong_predicted_pages:\n",
    "    page_image=cv2.imread(path,1)\n",
    "    wrong_predicted_page_images.append(page_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "show_numerical_batch(wrong_predicted_page_images, wrong_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(wrong_predicted_page_images):  \n",
    "    plt.figure(figsize=(5,7))\n",
    "    plt.grid(None)\n",
    "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
